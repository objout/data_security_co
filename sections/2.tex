\documentclass[../main.tex]{subfiles}
\graphicspath{{\subfix{../figures/}}}

\begin{document}
\section{技术原理及方法}
\subsection{威胁模型}
\subsubsection{学习的背景}
这里的威胁模型考虑多个参与者($ N \geqslant 2 $) 在各自本地的训练数据集上
联合训练全局模型的情况. 我们假设在这些参与者中存在一个或多个的攻击者,
攻击者的目的是模拟其他参与者的数据并污染全局模型, 而中央服务器和大多数的参与者
不存在恶意投毒的目的, 即中央服务器和绝大多数的参与者是可信任的.

在我们的威胁模型中, 攻击者在参与联邦学习的过程中只能访问全局的模型,
无法影响服务端的均值化算法和服务端对全局模型的更新. 同时, 所有的攻击者
均无法直接干扰其他非恶意参与者的训练过程和训练数据 $ D_{benign} $.
为了遵循联邦学习的约定, 攻击者还必须在投毒的数据 $ D_{poison} $
上正确训练和更新本地模型. 不失一般性和简单性, 这里的全局模型设定为图像分类器.
%
\subsubsection{攻击者的目标}
攻击者试图伪装成一般的参与者(非恶意的), 在训练阶段破坏全局模型.
在联邦学习的过程中, 攻击者在本地部署 GAN 生成模拟其他参与者的训练样本的数据,
并给这些样本赋以错误的标签, 将样本及标签加入攻击者本地的训练数据集中, 攻击者
的本地模型在这些投毒的数据上进行训练得到投毒的模型, 当攻击者本地的模型被服务端
选中并用某种算法更新到全局模型上, 污染就进一步传播到全局模型上. 此时, 全局模型
就具有攻击者所期望的某些性质.

攻击者的目标概括如下:
\begin{enumerate}
  \item 样本生成: 攻击者在不访问其他参与者的数据的情况下, 模拟生成其他参与者
    的训练数据.
  \item 提高投毒目标任务的性能: 经过投毒攻击的几轮模型迭代, 当攻击者本地投毒过的模型被更新到中央服务器的全局
    模型后, 全局模型应该在被投毒的分类任务上具有较高的预测性能.
  \item 提高主要目标任务的性能: 全局模型在其它未被投毒的分类任务上也应该具有
    较高的准确性, 以避免全局模型的表现不好被丢弃.
\end{enumerate}
%
\subsubsection{攻击者的能力}
\begin{itemize}
  \item 攻击者作为联邦学习的内部参与者之一, 可以在本地部署 GAN,
    修改本地训练的数据集, 调整训练过程, 发起\texttt{主动攻击(active attack)}.
  \item 攻击者对模型的结构有全面且清晰的了解, 因为所有联邦学习的参与者
    已经事先确定共同的学习目标.
\end{itemize}
%
\subsection{实施攻击}
\subsubsection{概述}
在联邦学习中实施投毒攻击有以下 $ 3 $ 个步骤:
\begin{enumerate}
  \item 基于 GAN 生成欲投毒样本并将其加入本地的训练数据集;
  \item 将生成的样本和错误的标签关联后注入训练过程,
    经过训练得到投毒的本地参数;
  \item 将投毒的本地模型上传至中央服务器, 旨在误导全局模型
    在推理阶段将输入分类为攻击者所期望的标签而非正确的.
\end{enumerate}
%
简明起见, 首先考虑有两个参与者(攻击者 $ A $ 和非恶意参与者 $ P $)
的联邦学习系统, 以此描述投毒攻击.

假定 $ P $ 和 $ A $ 分别训练分类类别 $ a $ 和类别 $ b $, 且 $ P $ 和
$ A $ 的学习目标和模型结构是一致的(联邦学习的约定).
在这种情况下, 类别 $ a $ 的信息对于 $ A $ 而言是不可见的.
攻击者的目标是模拟来自类别 $ a $ 的数据并实施投毒攻击.
因此, $ A $ 在本地部署 GAN(对中央服务器和 $ P $ 是不可见的),
以此产生来自类别 $ a $ 的模拟数据(将其标识为类别 $ b $), 并将这些数据注入本地的训练过程.
攻击者在投毒数据集的基础上训练模型, 并将所得模型上传至中央服务器.
因此, 通过增大投毒的规模, 便能在联邦学习系统中成功实施投毒攻击.
%
\subsubsection{生成投毒数据}
GAN 是两个神经网络间的对抗博弈, 即生成器 $ G $ 和判别器 $ D $.
判别器被训练来用于区分原始的数据和生成的数据, 而生成器被训练来用于
生成能够模拟判别器的训练数据的伪造数据. 为了模拟其他参与者的数据,
攻击者在本地采用 GAN, 将全局模型作为判别器. 经过不断地迭代后, 全局模型
将收敛. 对应地, 判别器会和全局模型同步, 引导生成器的收敛. 因此, 攻击者
可以使用这种方式生成高质量的伪造数据. 这些伪造的数据经过投毒会影响全局模型
在特定类别上的分类性能.
\subsubsection{基于 GAN 的投毒攻击}
%
\end{document}
