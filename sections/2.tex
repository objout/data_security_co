\documentclass[../main.tex]{subfiles}
\graphicspath{{\subfix{../figures/}}}

\begin{document}
\section{技术原理及方法}
\subsection{威胁模型}
\subsubsection{学习的背景}
这里的威胁模型考虑多个参与者($ N \geq 2 $) 在各自本地的训练数据集上
联合训练全局模型的情况. 我们假设在这些参与者中存在一个或多个的攻击者,
攻击者的目的是模拟其他参与者的数据并污染全局模型, 而中央服务器和大多数的参与者
不存在恶意投毒的目的, 即中央服务器和绝大多数的参与者是可信任的.

在我们的威胁模型中, 攻击者在参与联邦学习的过程中只能访问全局的模型,
无法影响服务端的均值化算法和服务端对全局模型的更新. 同时, 所有的攻击者
均无法直接干扰其他非恶意参与者的训练过程和训练数据 $ D_{benign} $.
为了遵循联邦学习的约定, 攻击者还必须在投毒的数据 $ D_{poison} $
上正确训练和更新本地模型. 不失一般性和简单性, 这里的全局模型设定为图像分类器.
%
\subsubsection{攻击者的目标}
攻击者试图伪装成一般的参与者(非恶意的), 在训练阶段破坏全局模型.
在联邦学习的过程中, 攻击者在本地部署 GAN 生成模拟其他参与者的训练样本的数据,
并给这些样本赋以错误的标签, 将样本及标签加入攻击者本地的训练数据集中, 攻击者
的本地模型在这些投毒的数据上进行训练得到投毒的模型, 当攻击者本地的模型被服务端
选中并用某种算法更新到全局模型上, 污染就进一步传播到全局模型上. 此时, 全局模型
就具有攻击者所期望的某些性质.

攻击者的目标概括如下:
\begin{enumerate}
  \item 样本生成: 攻击者在不访问其他参与者的数据的情况下, 模拟生成其他参与者
    的训练数据.
  \item 提高投毒目标任务的性能: 经过投毒攻击的几轮模型迭代, 当攻击者本地投毒过的模型被更新到中央服务器的全局
    模型后, 全局模型应该在被投毒的分类任务上具有较高的预测性能.
  \item 提高主要目标任务的性能: 全局模型在其它未被投毒的分类任务上也应该具有
    较高的准确性, 以避免全局模型的表现不好被丢弃.
\end{enumerate}
%
\subsubsection{攻击者的能力}
\begin{itemize}
  \item 攻击者作为联邦学习的内部参与者之一, 可以在本地部署 GAN,
    修改本地训练的数据集, 调整训练过程, 发起\texttt{主动攻击(active attack)}.
  \item 攻击者对模型的结构有全面且清晰的了解, 因为所有联邦学习的参与者
    已经事先确定共同的学习目标.
\end{itemize}
%
\subsection{实施攻击}
\subsubsection{概述}
在联邦学习中实施投毒攻击有以下 $ 3 $ 个步骤:
\begin{enumerate}
  \item 基于 GAN 生成欲投毒样本并将其加入本地的训练数据集;
  \item 将生成的样本和错误的标签关联后注入训练过程,
    经过训练得到投毒的本地参数;
  \item 将投毒的本地模型上传至中央服务器, 旨在误导全局模型
    在推理阶段将输入分类为攻击者所期望的标签而非正确的.
\end{enumerate}
%
简明起见, 首先考虑有两个参与者(攻击者 $ A $ 和非恶意参与者 $ P $)
的联邦学习系统, 以此描述投毒攻击.

假定 $ P $ 和 $ A $ 分别训练分类类别 $ a $ 和类别 $ b $, 且 $ P $ 和
$ A $ 的学习目标和模型结构是一致的(联邦学习的约定).
在这种情况下, 类别 $ a $ 的信息对于 $ A $ 而言是不可见的.
攻击者的目标是模拟来自类别 $ a $ 的数据并实施投毒攻击.
因此, $ A $ 在本地部署 GAN(对中央服务器和 $ P $ 是不可见的),
以此产生来自类别 $ a $ 的模拟数据(将其标识为类别 $ b $), 并将这些数据注入本地的训练过程.
攻击者在投毒数据集的基础上训练模型, 并将所得模型上传至中央服务器.
因此, 通过增大投毒的规模, 便能在联邦学习系统中成功实施投毒攻击.
%
\subsubsection{生成投毒数据}
GAN 是两个神经网络间的对抗博弈, 即生成器 $ G $ 和判别器 $ D $.
判别器被训练来用于区分原始的数据和生成的数据, 而生成器被训练来用于
生成能够模拟判别器的训练数据的伪造数据. 为了模拟其他参与者的数据,
攻击者在本地采用 GAN, 将全局模型作为判别器. 经过不断地迭代后, 全局模型
将收敛. 对应地, 判别器会和全局模型同步, 引导生成器的收敛. 因此, 攻击者
可以使用这种方式生成高质量的伪造数据. 这些伪造的数据经过投毒会影响全局模型
在特定类别上的分类性能.
\subsubsection{基于 GAN 的投毒攻击}
根据以上分析, 实施攻击的关键点是攻击者在本地的训练数据中投毒,
训练完成后将模型的更新 $ \Delta L^p $ 上传至中央服务器.
投毒攻击可归结为如下步骤:
\begin{enumerate}
  \item 假定 $ P $ 和 $ A $ 为联邦学习系统中的两个参与者,
    二者的训练数据集对其他参与者保密(类别 $ a $ 和 $ b $);
  \item 通过联邦学习迭代全局模型直至精度达到一定水平;
  \item 对于参与者 $ P $:
    \begin{enumerate}
      \item 下载全局模型以更新$ P $的本地模型;
      \item 在本地数据集上训练模型, 并将本地的更新 $ \Delta L^i $
        上传至中央服务器;
    \end{enumerate}
  \item 对于攻击者 $ A $:
    \begin{enumerate}
      \item 下载全局模型以更新 $ A $ 的本地模型;
      \item 复制新的本地模型, 将其作为 $ D $(判别器),
        在 $ D $ 的基础上运行 $ G $ (生成器) 以模拟
        $ P $ 的类别 $ a $ 中的数据;
      \item 将生成的类别 $ a $ 数据标记为类别 $ b $,
        并将数据插入到 $ A $ 的本地数据集中;
      \item 在投过毒的数据集上训练本地模型得到
        新的投毒的模型, 模型更新为 $ \Delta L^p $;
      \item 选定某个常数因子 $ \lambda $, 将 $ \Delta L^p $
        扩大对应的规模, 将投毒的更新 $ \lambda\Delta L^p $
        上传至中央服务器;
    \end{enumerate}
  \item 重复步骤 $ 3 $ 和 $ 4 $ 直到全局模型收敛.
\end{enumerate}
步骤 $ 4 $ 的子步骤 $ (2) $ 到 $ (5) $ 描述的是投毒数据的生成和
投毒攻击的实施. 这种投毒方法的效率仅取决于全局模型(判别器)的精确度.

拥有多个攻击者的一般化的投毒攻击在下面给出.

\begin{breakablealgorithm}
  \caption{联邦学习中的投毒攻击}
  \begin{algorithmic}
    \Require 全局模型 $ M_t $; 参与者对模型的更新 $ \Delta L_t^i $;
    损失函数 $ \mathcal{l} $; 学习率 $ \eta $.
    \Ensure 投毒的模型更新 $ \Delta \hat{L}_t^i $.
    \State 初始化生成器 $ G $ 和判别器 $ D $
    \For{$t \in (1, 2, \cdots, T)$}
    \State 将 $ M_t $ 发送给参与者 \Comment{服务端执行}
    \State 接收来自参与者的更新: $ \Delta L_{t+1}^i $
    \State 更新全局模型: $ M_{t+1} $
    \State 替换本地模型: $ L_t^i \gets M_t $ \Comment{参与者执行}
    \If{参与者是 $ A $(攻击者)}
    \State 根据新的本地模型 $ L_t^i $ 初始化 $ D $
    \For{$ \texttt{each epoch } e \in (1, \cdots, E) $}
    \State 在 $ D $ 的基础上为目标类别运行 $ G $
    \State 使用 $ D $ 更新 $ G $
    \State 使用 $ G $ 生成目标类别的样本
    \State 将错误的标签和生成的样本关联
    \State 将投毒数据注入本地训练数据集 $ \mathcal{D} $
    \For{$ \texttt{each batch } b_p \in \mathcal{D}_{poison} $}
    \State $ L_{t+1}^p = L_{t+1}^p - \eta_{adv}\nabla\mathcal{l}(L_t^p, b_p) $
    \EndFor
    \EndFor
    \State 计算投毒更新: $ \Delta L_{t+1}^p = L_{t+1}^p - L_t^p $
    \State 增大投毒规模: $ \Delta \hat{L}_{t+1}^p = \lambda \Delta L_{t+1}^p $;
    \Else
    \State 计算参与者的模型更新: $ \Delta L_{t+1}^i = L_{t+1}^i - L_t^i $;
    \EndIf
    \State 上传本地模型更新 $ \Delta L_{t+1}^i $(包含 $ \Delta \hat{L}_{t+1}^p $) 至中央服务器
    \EndFor
  \end{algorithmic}
\end{breakablealgorithm}
%
\end{document}
